{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HogOllboNkgR",
    "outputId": "3b313801-763d-45db-97b8-81819a5e0926"
   },
   "source": [
    "# This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "__mmB3vdNQwy"
   },
   "outputs": [],
   "source": [
    "import dask.bag as bag\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ur3JR9ZCNYzZ",
    "outputId": "2f60e9ed-0029-49d6-b58d-86ff7f6a847d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_wEvcZXwNuSZ"
   },
   "outputs": [],
   "source": [
    "raw_text = bag.read_text(\"/content/drive/MyDrive/foods.txt\",encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DNileglyN4Ai"
   },
   "outputs": [],
   "source": [
    "from dask.delayed import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Yvy53TnVN7Fq"
   },
   "outputs": [],
   "source": [
    "def get_next_buffer_part(file,start_index,span_index=0,blocksize=1000):\n",
    "    file.seek(start_index)\n",
    "    buffer = file.read(blocksize + span_index).decode('cp1252')\n",
    "    delimeter_position = buffer.find('\\n\\n')\n",
    "    if delimeter_position == -1:\n",
    "        return get_next_buffer_part(file,start_index,span_index+blocksize)\n",
    "    else:\n",
    "        file.seek(start_index)\n",
    "        return start_index,delimeter_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ivt8kTQQN-6Y"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/foods.txt\",\"rb\") as file_handle:\n",
    "    size = file_handle.seek(0,2) - 1       #Get the total size of the file in bytes\n",
    "    more_data = True                     \n",
    "    output = list()\n",
    "    current_position = next_position = 0\n",
    "    while more_data:\n",
    "        if current_position >= size:\n",
    "            more_data = False\n",
    "        else:\n",
    "            current_position,next_position = get_next_buffer_part(file_handle,current_position,0)\n",
    "            output.append((current_position,next_position))\n",
    "            current_position = current_position + next_position + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "otAQJdpXODMA"
   },
   "outputs": [],
   "source": [
    "def get_dict_item(filename,start_index,delimeter_position,encoding='cp1252'):\n",
    "    with open(filename,\"rb\") as file_handle:\n",
    "        file_handle.seek(start_index)\n",
    "        text = file_handle.read(delimeter_position).decode(encoding)\n",
    "        elements = text.strip().split(\"\\n\")\n",
    "        key_value_pairs = [(element.split(\": \")[0], element.split(\": \")[1])\n",
    "                          if len(element.split(\": \")) > 1\n",
    "                          else (\"unknown\",element)\n",
    "                          for element in elements]\n",
    "        return dict(key_value_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Qy7N0R9oODOs"
   },
   "outputs": [],
   "source": [
    "reviews = bag.from_sequence(output).map(lambda x: get_dict_item(\"/content/drive/MyDrive/foods.txt\",x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJBETCowODR_",
    "outputId": "0322be4e-8ee2-42df-c72a-bc91b9600bb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'product/productId': 'B001E4KFG0',\n",
       "  'review/helpfulness': '1/1',\n",
       "  'review/profileName': 'delmartian',\n",
       "  'review/score': '5.0',\n",
       "  'review/summary': 'Good Quality Dog Food',\n",
       "  'review/text': 'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.',\n",
       "  'review/time': '1303862400',\n",
       "  'review/userId': 'A3SGXH7AUHU8GW'},\n",
       " {'product/productId': 'B00813GRG4',\n",
       "  'review/helpfulness': '0/0',\n",
       "  'review/profileName': 'dll pa',\n",
       "  'review/score': '1.0',\n",
       "  'review/summary': 'Not as Advertised',\n",
       "  'review/text': 'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".',\n",
       "  'review/time': '1346976000',\n",
       "  'review/userId': 'A1D87F6ZCVE5NK'})"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KbFB5EQAOvEG"
   },
   "outputs": [],
   "source": [
    "def fetch_scores(element):\n",
    "    numeric_score = float(element['review/score'])\n",
    "    return numeric_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uMoNTh9pO3J6"
   },
   "outputs": [],
   "source": [
    "review_scores = reviews.map(fetch_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9g6KbSc8O6Ur"
   },
   "outputs": [],
   "source": [
    "def tag_reviews(element):\n",
    "    if float(element['review/score']) > 3:\n",
    "        element['review/score'] = 'pos'\n",
    "    else:\n",
    "        element['review/score'] = 'neg'\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3XqSwi48O-7v"
   },
   "outputs": [],
   "source": [
    "reviews = reviews.map(tag_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eWaBL52APBcz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from itertools import filterfalse\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IZlbiGvMPGvI"
   },
   "outputs": [],
   "source": [
    "def text_tokenization(x):\n",
    "    x['review/text'] = word_tokenize(x['review/text'])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "P1Fl61DFPUn4"
   },
   "outputs": [],
   "source": [
    "tokenized_reviews = reviews.map(text_tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LzDpHqUZPWj3"
   },
   "outputs": [],
   "source": [
    "def normalize_tokens(review):\n",
    "    review['review/text'] =  [x.lower() for x in review['review/text']]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JPpijKZIPY60"
   },
   "outputs": [],
   "source": [
    "normalized_reviews = tokenized_reviews.map(normalize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iMsgPgAvPbBr"
   },
   "outputs": [],
   "source": [
    "def contracted_word_expansion(token):\n",
    "    if token in contractions_dict.keys():\n",
    "        return contractions_dict[token]\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "cr4sSKb3PdBV"
   },
   "outputs": [],
   "source": [
    "def contractions_expansion(review):\n",
    "    review['review/text'] = list(map(contracted_word_expansion,review['review/text']))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Swkf_70CPfkh"
   },
   "outputs": [],
   "source": [
    "contracted_reviews = normalized_reviews.map(contractions_expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "R2yoL5j6Ph3m"
   },
   "outputs": [],
   "source": [
    "regex = r'^@[a-zA-z0-9]|^#[a-zA-Z0-9]|\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*|\\W+|\\d+|<(\"[^\"]*\"|\\'[^\\']*\\'|[^\\'\">])*>|_+|[^\\u0000-\\u007f]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cSMsQO1nPm-d"
   },
   "outputs": [],
   "source": [
    "def waste_word_or_not(token):\n",
    "    return re.search(regex,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "P6A7VByKPpNI"
   },
   "outputs": [],
   "source": [
    "def filter_waste_words(review):\n",
    "    review['review/text'] = list(filterfalse(waste_word_or_not,review['review/text']))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6V8Ybm8fPrQi"
   },
   "outputs": [],
   "source": [
    "filtered_reviews = contracted_reviews.map(filter_waste_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qRRokOVtPtc7"
   },
   "outputs": [],
   "source": [
    "def split(review):\n",
    "    review['review/text'] = list(map(lambda x: re.split(regex,x)[0],review['review/text']))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fDTVlVHXPv1N"
   },
   "outputs": [],
   "source": [
    "filtered_reviews = filtered_reviews.map(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7PtrR-tZlQX",
    "outputId": "972283e9-eef9-4561-9379-ea5eade4d989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "bxTND8MDPx9z"
   },
   "outputs": [],
   "source": [
    "en_stop_words = list(set(stopwords.words('english')).union(set(STOP_WORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ACdhiVrDP2pE"
   },
   "outputs": [],
   "source": [
    "def is_stopword(token):\n",
    "    return not(token in en_stop_words or re.search(r'\\b\\w\\b|[^\\u0000-\\u007f]+|_+|\\W+',token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "cGeooe2mP-Nk"
   },
   "outputs": [],
   "source": [
    "def stopwords_removal(review):\n",
    "    review['review/text'] = list(filter(is_stopword,review['review/text']))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ogefA1KSQAMd"
   },
   "outputs": [],
   "source": [
    "without_stopwords_reviews = filtered_reviews.map(stopwords_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "XQiJpuOCQCwv"
   },
   "outputs": [],
   "source": [
    "def get_wnet_pos_tag(treebank_tag):\n",
    "    wn.ensure_loaded()\n",
    "    if treebank_tag[1].startswith('J'):\n",
    "        return (treebank_tag[0],wn.ADJ)\n",
    "    elif treebank_tag[1].startswith('V'):\n",
    "        return (treebank_tag[0],wn.VERB)\n",
    "    elif treebank_tag[1].startswith('N'):\n",
    "        return (treebank_tag[0],wn.NOUN)\n",
    "    elif treebank_tag[1].startswith('R'):\n",
    "        return (treebank_tag[0],wn.ADV)\n",
    "    else:\n",
    "        return (treebank_tag[0],wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Sxr3vgXOQIle"
   },
   "outputs": [],
   "source": [
    "def get_pos_tag(review):\n",
    "    wn.ensure_loaded()\n",
    "    review['review/text'] = list(map(get_wnet_pos_tag,pos_tag(review['review/text'])))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "MdKtSh1YQLf2"
   },
   "outputs": [],
   "source": [
    "tagged_reviews = without_stopwords_reviews.map(get_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "aHAccY5cQNpA"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "wn.ensure_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "hFybISLEQRa4"
   },
   "outputs": [],
   "source": [
    "def token_lemmatization(token_pos_tuple):\n",
    "    wn.ensure_loaded()\n",
    "    if token_pos_tuple == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word=token_pos_tuple[0],pos=token_pos_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VZ1PuWmPQUpC"
   },
   "outputs": [],
   "source": [
    "def lemmatization(review):\n",
    "    wn.ensure_loaded()\n",
    "    if len(review['review/text']) > 0:\n",
    "        review['review/text'] = list(map(token_lemmatization,review['review/text']))\n",
    "    else:\n",
    "        review['review/text'] = [\"\"]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "IP9q1V_AQYM5"
   },
   "outputs": [],
   "source": [
    "lemmatized_reviews = tagged_reviews.map(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "VyhnaHTNQcrc"
   },
   "outputs": [],
   "source": [
    "def extract_tokens(review):\n",
    "    return review['review/text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "CxsJca6PQh0H"
   },
   "outputs": [],
   "source": [
    "extracted_tokens = lemmatized_reviews.map(extract_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "fvSMww_CQj7m"
   },
   "outputs": [],
   "source": [
    "unique_tokens = extracted_tokens.flatten().distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "_H70BoP7Ql1X"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VnzXMMnwbDwE",
    "outputId": "a8d63456-6062-4b8a-b7b6-4cd05d6eb941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNZFstg-bZr4",
    "outputId": "789350d4-d9be-4876-a7b9-ecdf79cd5792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/04/d5e0bb9f2cef5d15616ebf68087a725c5dbdd71bd422bcfb35d709f98ce7/contractions-0.0.48-py2.py3-none-any.whl\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n",
      "Collecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 15.2MB/s \n",
      "\u001b[?25hCollecting anyascii\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c7/61370d9e3c349478e89a5554c1e5d9658e1e3116cc4f2528f568909ebdf1/anyascii-0.1.7-py3-none-any.whl (260kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 13.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85402 sha256=60f5c1c3da61ddeeb64fc877a4e9b6439388a9d03b255b96bbcde6d4badb4fe5\n",
      "  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.1.7 contractions-0.0.48 pyahocorasick-1.4.2 textsearch-0.0.21\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "WrUG9nFrcH9h"
   },
   "outputs": [],
   "source": [
    "from contractions import contractions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8ohbqC4cRRP",
    "outputId": "a8f57724-38f2-433b-9b10-e8c383eb636a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AASZdZgQn3w",
    "outputId": "ace45dd0-0924-4c32-9b74-6c24538f4f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 19min 21.3s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    number_of_tokens = unique_tokens.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWqQ6z-9Qpwh",
    "outputId": "6d17464a-f63e-4d28-af8b-210395b6ee31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90271"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqBb1R4LQuVO",
    "outputId": "25d8e86e-ee23-4b8a-ecd6-5649a50d971f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<distinct-aggregate, npartitions=1>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5IngR9xQw8f",
    "outputId": "83a59732-1d3e-4858-b74a-5b714e3196fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 19min 12.9s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    tokens_index = list(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "CxC_vZmsQ1K0"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "dvTuKmtAQ1lw"
   },
   "outputs": [],
   "source": [
    "def compute_tf(review):\n",
    "    D = dict(Counter(review))\n",
    "    non_included = set(tokens_index).difference(set(D.keys()))\n",
    "    D_prime = dict(zip(non_included,list(np.zeros(len(non_included)))))\n",
    "    D_prime.update(D)\n",
    "    full_D = dict(OrderedDict(sorted(D_prime.items())))\n",
    "    print(full_D)\n",
    "    return np.array(full_D.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "pvjvvWB-Q3s1"
   },
   "outputs": [],
   "source": [
    "tf_vectors = extracted_tokens.map(compute_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ZvNjO4ImQ_eq"
   },
   "outputs": [],
   "source": [
    "def stacker(partition):\n",
    "    return dask_array.concatenate([element for element in partition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "56L70lWBRCoU",
    "outputId": "b0e4446d-b2a3-49fd-96be-c56469654074"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-823a00f75134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review/text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Bag' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "corpus = list()\n",
    "for text in reviews['review/text']:\n",
    "    corpus.append(text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Amazon-fine-food-reviews.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
